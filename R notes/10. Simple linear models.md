## Simple LR
Technique to predict a continuous outcome variable, Y, on the basis of one predictor variable, X, where
> Y=beta0​ + beta1​*X + error
- Where Y represents the continuous var
- Where X represents the predictor var
- Where beta_0 is the intercept, when X=0
- Where beta_1 is the coefficient of the line representing the relationship

To do this in R, we use `lm()`:
```r
model <- lm(outcome ~ indep_var, data = dataset)
```

## Train and test split 
Where a certain amount of data is used to train the model, and the remaining to increase the model's accuracy and generalizability.  

### Using `sample()`
Data can be randomly assigned to test/training using the `sample()` function in the `conversion_clean` data set:
```r
# specify 60/40 split, create data_sample variable
data_sample <- sample(c(TRUE, FALSE),
                      nrow(conversion_clean), #nos of rows in conversion_clean df
                      replace = TRUE, # each draw indep of other
                      prob = c(0.6, 0.4)) #60% true, 40% false draw
# subset into train and test using list (row) indexing
train <- conversion_clean[data_sample, ]   # rows where data_sample is TRUE
test  <- conversion_clean[!data_sample, ]  # rows where data_sample is FALSE
```
- **Square** brackets to be used for `train` and `test`!

### Using `rsample`
```r
library(rsample) #launch package
set.seed(42) # ensures reproducibility of RNG
split <- initial_split(df_name, prop = 0.7)  # 70% train, 30% test
train <- training(split)
test  <- testing(split)
```

We can then fit this to a linear regression model with `lm()`:
```r
model <- lm(response_var ~ predictor_var,
data = train/dataset)
```

### Quantifying model fit (Goodness of Fit)
1. **Residual squared error (RSE)**: Estimate of SD of error, by `summary(model)` or `sigma(model)`
2. **R squared**: Proportion of variance explained, by `summary(model)` or `summary(model)$r.squared`
   - e.g. `advertising_budget` explain 64% of the variability in the total `sales` value.

Using the example from codecademy:
```r
# compute r-squared for both models
r_sq <- summary(model)$r.squared 
r_sq_2 <- summary(model_2)$r.squared
```
Interpretation:
- Based on a pair of simple linear regression models, we have determined that 62.8% of the variation in user purchase behavior can be explained by the number of times a user viewed on a relevant ad campaign;
- Whereas only 43.3% of this variation can be explained by the number of times a user clicked on a relevant ad.

**To extract coefficients**, for example, in `model_2 <- lm(labor_income ~ education_years + age + gender, data = train)`, for `education_years`:
```r
education_coefficient <- model_2$coefficients[2]
```

3. **Residual calculation**: Vertical distance between a datapoint and the line estimated by a regression model
To obtain the points which form the (1) estimate line, and (2) residual values, use the `predict()` and `residuals()` functions.  

For example, in the `train` dataset:
```r
#save predicted and residual values to df
train$estimate <- predict(model) # saved to column named estimate
train$residuals <- residuals(model) # saved to column named residuals
```

To plot the observed data points from the `train` dataset, where y = `estimate`:
```r
#create visualization
plot <- ggplot(data = train, aes(x=clicks, y=total_convert)) +
geom_point(aes(size = abs(residuals))) + # plots data points, and sizes them according to abs size of residuals
geom_point(aes(y=estimate),color = "blue") +
geom_segment(aes(xend = clicks, yend = estimate), color = "gray") # add vertical distance between observed points and estimate line
```

4. **LOESS (Locally Estimated Scatterplot Smoothing) in R**: Plots a line based on the weighted value of data points. It cannot be used to predict new values, since it relies heavily on training data, but is a helpful tool for visualising where the linear data diverges from training data.  

To plot the LOESS model,
```r
plot <- ggplot(train, aes(predictor_var, response_var)) +
geom_point() + 
geom_smooth(method = "lm") + # plots linear regression line
geom_smooth(se = FALSE, color = "red") #plots LOESS line and se to hide confidence interval
```

### Interpreting model results
Using the `summary()` function, with `model_name` passed as the argument.
<img width="763" height="509" alt="image" src="https://github.com/user-attachments/assets/a21d549c-6d1c-4a0c-baa6-7d107fdcc661" />
- `t value` and `Pr(>|t|)` answer the same question - given the the value of our variable’s regression coefficient and its’ standard error, does the variable explain a significant part of the change in our outcome variable?
- However, the `Pr(>|t|)` column purposely provides a more concise response to this question, using the asterisk notation that corresponds with the `Signif. codes` legend at the bottom of the Coefficients results section.
- Generally speaking, scientists accept that a **variable coefficient with p-value < 0.05** is statistically significant.
- The `intercept` coefficient is **different** from the variable coeffs, as it represents the value of the `outcome_var` when the `predictor_var` is zero; In other words, Y when X = 0.
- **It is crucial to remember that the intercept coefficient is only interpretable if we can reasonably expect a zero value for all independent variables in a model**.

### Predicting future values
We can **calculate training MSE** for `model` using a combination of `add_predictions()` and `summarise()`.
- `add_predictions()` creates and adds predicted values from a model to a column called `pred`.
- `summarise()` then allows us to calculate the squared difference between our predicted values `pred` and observed values `sales`.

For example, when testing with `train` data:
```r
train %>% 
  add_predictions(model) %>% # add predicted values
  summarise(MSE = mean((sales - pred)^2))
       MSE #attain output
  31.60713
```
- Must ensure that there is no substantial difference between model training & test MSE
